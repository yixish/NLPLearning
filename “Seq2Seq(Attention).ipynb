{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "â€œSeq2Seq(Attention)",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yixish/NLPLearning/blob/master/%E2%80%9CSeq2Seq(Attention).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9YIkuxFQWDS"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as Data\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oH2A4ikIQWDg"
      },
      "source": [
        "Set the random seeds for reproducability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ON-iFjcQWDg"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeiGsd8Be4aK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca32709d-7efa-44bf-c48f-c169fa95138a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ubcuIsPYixj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29b019d4-d7b3-4e9f-a345-c54d28f6e065"
      },
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Nov 19 04:19:21 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OA60iC5KhunC"
      },
      "source": [
        "import pandas as pd \n",
        "dir = '/content/gdrive/My Drive/dataset/'\n",
        "df = pd.read_csv(dir+\"Sentiment_Extraction103/train.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiMdKZebQWDq"
      },
      "source": [
        "Load the German and English spaCy models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyLs68Fle_r1"
      },
      "source": [
        "texts = df['text'].values\n",
        "selected_texts = df['selected_text'].values\n",
        "num = 4096\n",
        "texts = texts[:num]\n",
        "selected_texts = selected_texts[:num]\n",
        "pairs = []\n",
        "for i in range(num):\n",
        "    pairs.append([texts[i],selected_texts[i]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yrw9UiISfFBS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6204b791-ac45-4ceb-f01f-b957e3964e9d"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-MIq8wLfFtY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3454ae11-dbbf-4248-ad87-eefbe239b0ad"
      },
      "source": [
        "vocab = set()\n",
        "vocab.add('<sos>')\n",
        "vocab.add('<eos>')\n",
        "vocab.add('<pad>')\n",
        "vocab.add('<unk>')\n",
        "\n",
        "def build_vocab(vocab,texts):\n",
        "    max_l = 0\n",
        "    for text in texts:\n",
        "        words = nltk.word_tokenize(text)\n",
        "        if max_l < len(words):\n",
        "            max_l = len(words)\n",
        "        for word in words:\n",
        "            vocab.add(word)\n",
        "    print(max_l)\n",
        "build_vocab(vocab,texts)\n",
        "build_vocab(vocab,selected_texts)\n",
        "print(\"vocal size : {}\".format(len(vocab)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "52\n",
            "40\n",
            "vocal size : 10503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v1GG8fpfHt5"
      },
      "source": [
        "word2idx = { word:i for i,word in enumerate(list(vocab))}\n",
        "idx2word = { i:word for i,word in enumerate(list(vocab))}                         "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_SRJzsnfJ2s"
      },
      "source": [
        "n_step = 55\n",
        "batch_size = 128\n",
        "n_hidden = 128\n",
        "emb_dim = 100\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "def make_data(seq_data):\n",
        "    enc_input_all, dec_input_all, dec_output_all = [], [], []\n",
        "\n",
        "    def word_2_idx(word):\n",
        "        if word in vocab:\n",
        "            return word2idx[word]\n",
        "        else: \n",
        "            return word2idx['<unk>']\n",
        "\n",
        "    for seq in seq_data:\n",
        "        enc_input = []\n",
        "        enc_input.append(word2idx['<sos>'])\n",
        "        enc_input.extend([word_2_idx(n) for n in  nltk.word_tokenize(seq[0])])\n",
        "        enc_input.append(word2idx['<eos>'])\n",
        "        dec_input = []\n",
        "        dec_input.append(word2idx['<sos>'])\n",
        "        dec_input.extend([word_2_idx(n) for n in nltk.word_tokenize(seq[1])])\n",
        "        enc_input.append(word2idx['<eos>'])\n",
        "\n",
        "        dec_output = [word_2_idx(n) for n in nltk.word_tokenize(seq[1])] \n",
        "        dec_output.append(word2idx['<eos>'])\n",
        "\n",
        "        for i in range(n_step - len(enc_input)):\n",
        "            enc_input.append(word2idx['<pad>'])\n",
        "        for i in range(n_step - len(dec_input)):\n",
        "            dec_input.append(word2idx['<pad>'])\n",
        "        for i in range(n_step - len(dec_output)):\n",
        "            dec_output.append(word2idx['<pad>'])\n",
        "\n",
        "        enc_input_all.append(enc_input)\n",
        "        dec_input_all.append(dec_input)\n",
        "        dec_output_all.append(dec_output) \n",
        "\n",
        "    # make tensor\n",
        "    return torch.LongTensor(enc_input_all), torch.LongTensor(dec_input_all), torch.LongTensor(dec_output_all)\n",
        "\n",
        "enc_input_all, dec_input_all, dec_output_all = make_data(pairs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLsKqdMufSUX"
      },
      "source": [
        "class TranslateDataSet(Data.Dataset):\n",
        "    def __init__(self, enc_input_all, dec_input_all, dec_output_all):\n",
        "        self.enc_input_all = enc_input_all\n",
        "        self.dec_input_all = dec_input_all\n",
        "        self.dec_output_all = dec_output_all\n",
        "    \n",
        "    def __len__(self): # return dataset size\n",
        "        return len(self.enc_input_all)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.enc_input_all[idx], self.dec_input_all[idx], self.dec_output_all[idx]\n",
        "\n",
        "loader = Data.DataLoader(TranslateDataSet(enc_input_all, dec_input_all, dec_output_all), batch_size, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_No_GgVGQWEb"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57nfv01ZQWEf"
      },
      "source": [
        "Create the iterators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY7wvjYfQWEk"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src): \n",
        "        '''\n",
        "        src = [src_len, batch_size]\n",
        "        '''\n",
        "        src = src.transpose(0, 1) # src = [batch_size, src_len]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(src)).transpose(0, 1) # embedded = [src_len, batch_size, emb_dim]\n",
        "\n",
        "        # enc_output = [src_len, batch_size, hid_dim * num_directions]\n",
        "        # enc_hidden = [n_layers * num_directions, batch_size, hid_dim]\n",
        "        enc_output, enc_hidden = self.rnn(embedded) # if h_0 is not give, it will be set 0 acquiescently\n",
        "\n",
        "        # enc_hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
        "        # enc_output are always from the last layer\n",
        "        \n",
        "        # enc_hidden [-2, :, : ] is the last of the forwards RNN \n",
        "        # enc_hidden [-1, :, : ] is the last of the backwards RNN\n",
        "        # initial decoder hidden is final hidden state of the forwards and backwards \n",
        "        # encoder RNNs fed through a linear layer\n",
        "        # s = [batch_size, dec_hid_dim]\n",
        "        s = torch.tanh(self.fc(torch.cat((enc_hidden[-2,:,:], enc_hidden[-1,:,:]), dim = 1)))\n",
        "        \n",
        "        return enc_output, s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7IJ0v66QWEv"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim, bias=False)\n",
        "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
        "        \n",
        "    def forward(self, s, enc_output):\n",
        "        \n",
        "        # s = [batch_size, dec_hid_dim]\n",
        "        # enc_output = [src_len, batch_size, enc_hid_dim * 2]\n",
        "        \n",
        "        batch_size = enc_output.shape[1]\n",
        "        src_len = enc_output.shape[0]\n",
        "        \n",
        "        # repeat decoder hidden state src_len times\n",
        "        # s = [batch_size, src_len, dec_hid_dim]\n",
        "        # enc_output = [batch_size, src_len, enc_hid_dim * 2]\n",
        "        s = s.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        enc_output = enc_output.transpose(0, 1)\n",
        "        \n",
        "        # energy = [batch_size, src_len, dec_hid_dim]\n",
        "        energy = torch.tanh(self.attn(torch.cat((s, enc_output), dim = 2)))\n",
        "        \n",
        "        # attention = [batch_size, src_len]\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "        \n",
        "        return F.softmax(attention, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIvuL5awQWE0"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, dec_input, s, enc_output):\n",
        "             \n",
        "        # dec_input = [batch_size]\n",
        "        # s = [batch_size, dec_hid_dim]\n",
        "        # enc_output = [src_len, batch_size, enc_hid_dim * 2]\n",
        "        \n",
        "        dec_input = dec_input.unsqueeze(1) # dec_input = [batch_size, 1]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(dec_input)).transpose(0, 1) # embedded = [1, batch_size, emb_dim]\n",
        "        \n",
        "        # a = [batch_size, 1, src_len]  \n",
        "        a = self.attention(s, enc_output).unsqueeze(1)\n",
        "        \n",
        "        # enc_output = [batch_size, src_len, enc_hid_dim * 2]\n",
        "        enc_output = enc_output.transpose(0, 1)\n",
        "\n",
        "        # c = [1, batch_size, enc_hid_dim * 2]\n",
        "        c = torch.bmm(a, enc_output).transpose(0, 1)\n",
        "\n",
        "        # rnn_input = [1, batch_size, (enc_hid_dim * 2) + emb_dim]\n",
        "        rnn_input = torch.cat((embedded, c), dim = 2)\n",
        "            \n",
        "        # dec_output = [src_len(=1), batch_size, dec_hid_dim]\n",
        "        # dec_hidden = [n_layers * num_directions, batch_size, dec_hid_dim]\n",
        "        dec_output, dec_hidden = self.rnn(rnn_input, s.unsqueeze(0))\n",
        "        \n",
        "        # embedded = [batch_size, emb_dim]\n",
        "        # dec_output = [batch_size, dec_hid_dim]\n",
        "        # c = [batch_size, enc_hid_dim * 2]\n",
        "        embedded = embedded.squeeze(0)\n",
        "        dec_output = dec_output.squeeze(0)\n",
        "        c = c.squeeze(0)\n",
        "        \n",
        "        # pred = [batch_size, output_dim]\n",
        "        pred = self.fc_out(torch.cat((dec_output, c, embedded), dim = 1))\n",
        "        \n",
        "        return pred, dec_hidden.squeeze(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64wJqu2TQWE4"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        # src = [batch_size,src_len]\n",
        "        # trg = [batch_size,trg_len]\n",
        "        # teacher_forcing_ratio is probability to use teacher forcing\n",
        "\n",
        "        src = src.transpose(0,1)\n",
        "        trg = trg.transpose(0,1)\n",
        "        \n",
        "        batch_size = src.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        # tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "\n",
        "        # enc_output is all hidden states of the input sequence, back and forwards\n",
        "        # s is the final forward and backward hidden states, passed through a linear layer\n",
        "        enc_output, s = self.encoder(src)\n",
        "                \n",
        "        # first input to the decoder is the <sos> tokens\n",
        "        dec_input = trg[0,:]\n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            # insert dec_input token embedding, previous hidden state and all encoder hidden states\n",
        "            # receive output tensor (predictions) and new hidden state\n",
        "            dec_output, s = self.decoder(dec_input, s, enc_output)\n",
        "            \n",
        "            # place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = dec_output\n",
        "            \n",
        "            # decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            # get the highest predicted token from our predictions\n",
        "            top1 = dec_output.argmax(1) \n",
        "            # if teacher forcing, use actual next token as next input\n",
        "            # if not, use predicted token\n",
        "            dec_input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXpZLK3xQWE-"
      },
      "source": [
        "# INPUT_DIM = len(SRC.vocab)\n",
        "# OUTPUT_DIM = len(TRG.vocab)\n",
        "INPUT_DIM = vocab_size\n",
        "OUTPUT_DIM  = vocab_size\n",
        "ENC_EMB_DIM = 128\n",
        "DEC_EMB_DIM = 128\n",
        "ENC_HID_DIM = 256\n",
        "DEC_HID_DIM = 256\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnYtPpQSfwfO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eb707bc-7782-4af5-e0c4-79b734eb466f"
      },
      "source": [
        "for epoch in range(600):\n",
        "  for enc_input_batch, dec_input_batch, dec_output_batch in loader:\n",
        "\n",
        "      (enc_input_batch, dec_intput_batch,dec_output_batch) = (enc_input_batch.to(device), dec_input_batch.to(device),dec_output_batch.to(device))\n",
        "\n",
        "      # enc_input_batch : [batch_size, seq_len]\n",
        "      # dec_intput_batch : [batch_size, seq_len]\n",
        "      pred = model(enc_input_batch,dec_intput_batch,0.5)\n",
        "\n",
        "      # pred : [seq_len, batch_size, n_class]\n",
        "      pred = pred.transpose(0, 1) # [batch_size, seq_len, n_class]\n",
        "      \n",
        "      loss = 0\n",
        "      for i in range(len(dec_output_batch)):\n",
        "          # pred[i] : [n_step+1, n_class]\n",
        "          # dec_output_batch[i] : [n_step+1]\n",
        "          loss += criterion(pred[i], dec_intput_batch[i])\n",
        "      if (epoch + 1) % 20 == 0:\n",
        "          print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
        "          \n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0020 cost = 99.468361\n",
            "Epoch: 0020 cost = 120.809807\n",
            "Epoch: 0020 cost = 131.646545\n",
            "Epoch: 0020 cost = 126.819580\n",
            "Epoch: 0020 cost = 99.441719\n",
            "Epoch: 0020 cost = 106.268974\n",
            "Epoch: 0020 cost = 112.493080\n",
            "Epoch: 0020 cost = 103.276535\n",
            "Epoch: 0020 cost = 107.548080\n",
            "Epoch: 0020 cost = 126.513344\n",
            "Epoch: 0020 cost = 106.313904\n",
            "Epoch: 0020 cost = 106.663177\n",
            "Epoch: 0020 cost = 120.643242\n",
            "Epoch: 0020 cost = 111.529442\n",
            "Epoch: 0020 cost = 122.860901\n",
            "Epoch: 0020 cost = 102.154327\n",
            "Epoch: 0020 cost = 111.610115\n",
            "Epoch: 0020 cost = 97.127991\n",
            "Epoch: 0020 cost = 114.804085\n",
            "Epoch: 0020 cost = 110.764473\n",
            "Epoch: 0020 cost = 101.264679\n",
            "Epoch: 0020 cost = 139.141113\n",
            "Epoch: 0020 cost = 103.057610\n",
            "Epoch: 0020 cost = 115.133331\n",
            "Epoch: 0020 cost = 128.842957\n",
            "Epoch: 0020 cost = 105.130196\n",
            "Epoch: 0020 cost = 117.187737\n",
            "Epoch: 0020 cost = 125.735260\n",
            "Epoch: 0020 cost = 111.985741\n",
            "Epoch: 0020 cost = 117.433884\n",
            "Epoch: 0020 cost = 114.806725\n",
            "Epoch: 0020 cost = 130.278015\n",
            "Epoch: 0040 cost = 64.025581\n",
            "Epoch: 0040 cost = 63.655861\n",
            "Epoch: 0040 cost = 61.609425\n",
            "Epoch: 0040 cost = 56.766514\n",
            "Epoch: 0040 cost = 62.067745\n",
            "Epoch: 0040 cost = 56.979427\n",
            "Epoch: 0040 cost = 59.133522\n",
            "Epoch: 0040 cost = 63.683453\n",
            "Epoch: 0040 cost = 62.760624\n",
            "Epoch: 0040 cost = 64.603188\n",
            "Epoch: 0040 cost = 55.855560\n",
            "Epoch: 0040 cost = 61.482277\n",
            "Epoch: 0040 cost = 53.977379\n",
            "Epoch: 0040 cost = 56.535019\n",
            "Epoch: 0040 cost = 53.737053\n",
            "Epoch: 0040 cost = 67.421753\n",
            "Epoch: 0040 cost = 62.538639\n",
            "Epoch: 0040 cost = 60.617420\n",
            "Epoch: 0040 cost = 57.386696\n",
            "Epoch: 0040 cost = 62.079685\n",
            "Epoch: 0040 cost = 63.801250\n",
            "Epoch: 0040 cost = 65.947449\n",
            "Epoch: 0040 cost = 57.089649\n",
            "Epoch: 0040 cost = 64.958405\n",
            "Epoch: 0040 cost = 69.169479\n",
            "Epoch: 0040 cost = 52.969082\n",
            "Epoch: 0040 cost = 53.352596\n",
            "Epoch: 0040 cost = 61.435646\n",
            "Epoch: 0040 cost = 70.624001\n",
            "Epoch: 0040 cost = 58.320263\n",
            "Epoch: 0040 cost = 61.176922\n",
            "Epoch: 0040 cost = 62.752304\n",
            "Epoch: 0060 cost = 37.940907\n",
            "Epoch: 0060 cost = 37.682495\n",
            "Epoch: 0060 cost = 35.421177\n",
            "Epoch: 0060 cost = 38.059654\n",
            "Epoch: 0060 cost = 35.511509\n",
            "Epoch: 0060 cost = 39.666870\n",
            "Epoch: 0060 cost = 39.369064\n",
            "Epoch: 0060 cost = 40.743893\n",
            "Epoch: 0060 cost = 35.891552\n",
            "Epoch: 0060 cost = 36.333420\n",
            "Epoch: 0060 cost = 39.576363\n",
            "Epoch: 0060 cost = 38.987240\n",
            "Epoch: 0060 cost = 36.228012\n",
            "Epoch: 0060 cost = 41.098820\n",
            "Epoch: 0060 cost = 37.861938\n",
            "Epoch: 0060 cost = 37.772976\n",
            "Epoch: 0060 cost = 36.819588\n",
            "Epoch: 0060 cost = 38.361073\n",
            "Epoch: 0060 cost = 42.093758\n",
            "Epoch: 0060 cost = 37.093983\n",
            "Epoch: 0060 cost = 38.786583\n",
            "Epoch: 0060 cost = 36.939949\n",
            "Epoch: 0060 cost = 36.988213\n",
            "Epoch: 0060 cost = 36.271347\n",
            "Epoch: 0060 cost = 37.322842\n",
            "Epoch: 0060 cost = 40.689106\n",
            "Epoch: 0060 cost = 36.531548\n",
            "Epoch: 0060 cost = 36.776154\n",
            "Epoch: 0060 cost = 37.170021\n",
            "Epoch: 0060 cost = 38.195610\n",
            "Epoch: 0060 cost = 39.333504\n",
            "Epoch: 0060 cost = 41.582237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHQKT3J0sIwK"
      },
      "source": [
        "# Test\n",
        "def translate(word):\n",
        "    enc_input, dec_input, dec_output = make_data([[word, '']])\n",
        "\n",
        "\n",
        "    enc_input, dec_input = enc_input.to(device), dec_input.to(device)\n",
        "    # make hidden shape [num_layers * num_directions, batch_size, n_hidden]\n",
        "    # hidden = torch.zeros(1, 1, n_hidden).to(device)\n",
        "    # output = model(enc_input, hidden, dec_input)\n",
        "    output = model(enc_input, dec_input, 0)\n",
        "\n",
        "    # output : [n_step+1, batch_size, n_class]\n",
        "\n",
        "    predict = output.data.max(2, keepdim=True)[1] # select n_class dimension\n",
        "    decoded = [idx2word[i.item()] for i in predict]\n",
        "    print(decoded)\n",
        "    if '<pad>' in decoded:\n",
        "        translated = ' '.join(decoded[:decoded.index('<pad>')])\n",
        "        translated = translated.replace('<eos>','')\n",
        "        return translated\n",
        "    else:\n",
        "        return (\" \".join(decoded)).replace('<eos>','')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW35UtlPsQpg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83d94067-1a43-4d16-dd1e-c6c4ba0fd9f9"
      },
      "source": [
        "for sent in pairs[:5]:\n",
        "    print(\"{} => {}\".format(sent[1], translate(sent[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['can`t', 'love', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "love => can`t love\n",
            "['can`t', 'Starbucks', 'I`m', 'lovin`', 'it', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Starbucks I`m lovin` it => can`t Starbucks I`m lovin` it\n",
            "['can`t', '.yummmmy', '!', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            ".yummmmy! => can`t .yummmmy !\n",
            "['can`t', 'Hello', ',', 'I', 'see', 'your', 'online', ',', 'can', 'u', 'talk', 'to', 'me', 'pleeez', '!', 'From', 'a', 'fellow', 'BAMF', '.', 'lol', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Hello, I see your online, can u talk to me pleeez!  From a fellow BAMF. lol => can`t Hello , I see your online , can u talk to me pleeez ! From a fellow BAMF . lol\n",
            "['can`t', 'fun', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "fun => can`t fun\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btV8JGubZPf4"
      },
      "source": [
        "test_df = pd.read_csv(dir+\"Sentiment_Extraction103/test.csv\")\n",
        "words_voc = ['helped', 'sry',  'scratchy', 'pray', 'fighting', 'aw', 'crazy', 'Won', 'perfect', 'couldnt', 'expected', 'Clever', 'irked', 'excellent', 'luvin', 'losing', 'Gutted', 'busy', 'failing', 'gd', 'bothered', 'attacked', 'rofl', 'scaring', 'shut', 'Good', 'friendly', 'respect', 'nab', 'sux', 'ashamed', 'HORRIBLE', 'Luckily', 'relief', 'stepped', 'hahahaha', 'RIP', 'hell', 'Scared', 'popular', 'gut', 'congrats', 'repair', 'painting', 'freed', 'sadifying', 'barely', 'morning', 'weLcomE', 'Happeh', 'Byebye', 'unfair', 'yaay', 'Aww', 'Addicted', 'accident', 'terrible', 'baffles', 'cramps', 'Also', 'laughs', 'boring', 'yeah', 'deserve', 'fault', 'honored', 'COOL', 'forgets', 'crying', 'welcome', 'amazing', 'funny', 'ave', 'sarcy', 'Hope', 'Awe', 'barked', 'Awsome', 'Burnt', 'brutal', 'hyper', 'healthy', 'bruise', 'nicest', 'harder', 'hard', 'rubbish', 'mourning', 'Friends', 'scary', 'ily', 'heartless', 'rocks', 'Stunning', 'Finally', 'boak', 'painful', 'Sor', 'Sunburned', 'Yummm', 'cooler', 'effective', 'precise', 'chocked', 'banging', 'Chilliin', 'mope', 'Crappy', 'help', 'ouch', 'believe', 'Sorr', 'refuses', 'sukked', 'wrong', 'corrupted', 'pain', 'toothache', 'Neat', 'pissing', 'buried', 'inflating', 'grimmy', 'puke', 'ruined', 'fantastic', 'impostor', 'grateful', 'Awwww', 'problems', 'lovingly', 'panic', 'FORCED', 'dreary', 'lov', 'talented', 'yey', 'wo', 'strong', 'blast', 'poorly', 'Healthy', 'hacked', 'dying', 'SUCK', 'Overheat', 'BAD', 'Liked', 'precious', 'killing', 'heyy', 'thanks', 'strep', 'proudly', 'destroy', 'Yesssssir', 'missin', 'unrelated', 'Lol', 'Wtf', 'sFunF', 'welts', 'Sickkkk', 'lonley', 'confsuing', 'tough', 'low', 'fight', 'Boreedd', 'Bore', 'night', 'hit', 'Honestly', 'wonderful', 'dream', 'Yum', 'hating', 'ow', 'wrecked', 'ENJOY', 'delcious', 'Pinkberry', 'gloomy', 'starbuck', 'SCOREless', 'ultimate', 'ughhhh', 'Thanx', 'awwww', 'WELCOME', 'loosing', 'Morning', 'Enjoyed', 'Thanks', 'Awesome', 'lacking', 'Welcome', 'bask', 'GREAT', 'FUN', 'Scarred', 'Congrats', 'Yeahhhhh', 'Beautiful', 'useless', 'Cutie', 'dang', 'limp', 'failed', 'stop', 'shocked', 'snob', 'heavy', 'YUCK', 'funn', 'Hate', 'troubles', 'Boring', 'partying', 'tyvm', 'thaank', 'fave', 'glorious', 'wonder', 'HEADACHE', 'cried', 'dieing', 'Thanxxx', 'salute', 'hat', 'trouble', 'headaches', 'TY', 'bloody', 'ahmazing', 'bugs', 'sorry', 'Needless', 'enjoys', 'Uggh', 'happy', 'Poor', 'Hooray', 'ugly', 'braggin', 'yaaaaaay', 'ilove', 'celebrate', 'sweeet', 'thx', 'no', 'aww', 'well', 'UPSET', 'omg', 'horrific', 'break', 'yummy', 'warm', 'Stupid', 'annoyed-y', 'disliking', 'uprooted', 'freakin', 'best', 'play', 'sick', 'positive', 'GOOD', 'Blushing', 'impressed', 'Hard', 'fresh', 'sexy', 'acing', 'exhausted', 'annoying', 'food', 'nasty', 'sicker', 'Hahahaha', 'thinking', 'boo', 'rotten', 'Harder', 'Ugh', 'lucky', '-hugs', 'Horrible', 'Dead', 'funniest', 'save', 'boohoohoo', 'fancy', 'fav', 'Bummer', 'Ouch', 'fail', 'headach', 'sosad', 'top', 'faults', 'Loves', 'goood', 'fear', 'boffert', 'sucks', 'easy', 'negative', 'kiss', 'hoping', 'pleeeease', 'injury', 'bettering', 'honest', 'Thanxx', 'helping', 'jealous-', 'silly', 'same', 'thank/', 'shattered', 'bestest', 'wiff', 'likes', 'FAIL', 'Roasting', 'screams', 'cutest', 'disgusted', 'Blessed', 'stressful', 'Awww', 'AWESOME', 'loving', 'inlove', 'Missed', 'separates', 'Yuuum', 'toughest', 'cancelled', 'thanx', 'bummer', 'fool', 'lammmeeee', 'pooooor', 'blunt', 'worse', 'suck', 'wow', 'Luv', 'Sorry', 'cold', 'dead', 'Refreshed', 'denied', 'disagree', 'Hugs', 'Sweet', 'yum', 'thnks', 'burned', 'glamorous', 'survive', 'buggin', 'Link', 'annoyed', 'difficult', 'hurting', 'exciting', 'cheer', 'thankful', 'delayed', 'cheered', 'argue', 'bother', 'laughing', 'AWFUL', 'please', 'nothing', 'pisses', 'Kudos', 'cruel', 'amazes', 'heat', 'homesick', 'illogical', 'though', 'urgh', 'happpy', 'blew', 'piss', 'oops', 'perfectly', 'Use', 'bitbetter', 'defective', 'lovin', 'energy', 'OMFG', '_violence', 'sickness', 'dismal', 'down', 'recommend', 'working', 'bleeds', 'warmly', 'spilled', 'glad', 'sore', 'LOVED', 'Hurray', 'yep', 'amaze', 'ignoring', 'Wishes', 'beasted', 'cries', 'Favorite', 'headache', 'sunburnt', 'fcking', 'yay', 'honor', 'cool', 'hopefuly', 'wish', 'HATE', 'ANGRY', 'fml', 'pricey', 'weirdos', 'accidents', 'miserable', 'dammit', 'blessed', 'slow', 'Thankyou', 'Annoyed', 'HAPP', 'excited', 'lose', 'homework', 'thankies', 'clean', 'comfy', 'suffering', 'credit', 'luvd', 'surprised', 'Foolish', 'pity', 'reunited', 'Goood', 'gooood', 'abuse', 'hungry', 'better', 'Liking', 'Gratiss', 'thanxx', 'awesomest', 'Pissed', 'booted', 'bricked', 'gutted', 'cry', 'sober', 'DANG', 'yayay', 'killed', 'douchebag', 'agitated', 'spammer', 'Muses', 'pleasure-', 'unable', 'bad', 'killen', 'goodness', 'spamming', 'slacking', 'stressed', 'willing', 'Loving', 'DIE', 'fabulous', 'Enjoy', 'burning', 'ing', 'tricked', 'sunny', 'shitt', 'Haha', 'writing', 'loose', 'effed', 'poked', 'robbed', 'coolest', 'Cried', 'destroys', 'confused', 'strikes', 'lovely', 'misses', 'loss', 'shitttt', 'win', 'stuffed', 'excuse', 'fans', 'boredom', 'sadly', 'priceless', 'hater', 'funnnn', 'spammers', 'lazy', 'angry', 'Stressed', 'Worried', 'goo', 'sense', 'good', 'feel', 'Upset', 'Rejected', 'ROCKED', 'filthy', 'Sucks', 'worry', 'waste', 'ugh', 'die', 'ill', 'Mad', 'afraid', 'Cute', 'soooory', 'NICE', 'sucked', 'careless', 'Awaiting', 'avoid', 'underpaid', 'Happy', 'true', 'LOVES', 'dragged', 'jealous', 'Hitting', 'Glad', 'Wishing', 'worth', 'nooooooo', 'hate', 'Gorgeous', 'distorted', 'hurtin', 'anymore', 'awww', 'shucks', 'laavly', 'soft', 'saddest', 'haha', 'busted', 'restful', 'recharge', 'bahaha', 'Goodnit', 'awwwww', 'smack', 'nervous', 'the', 'dread', 'Gudluck', 'suckss', 'hahah', 'retarded', 'stuck', 'relaxing', 'Miss', 'dancing', 'lie', 'rough', 'cheers', 'grand', 'unhappy', 'spoiled', 'stopped', 'stronger', 'Loved', 'loves', 'proud', 'endure', 'chilly', 'doomed', 'endearing', 'loll', 'Sad', 'sadd', 'forgot', 'wtf', 'sinking', 'attacking', 'Rejecting', 'breaks', 'friends', 'pleasure', 'Bliss', 'crashed', 'hapee', 'hehe', 'lies', 'touche', 'death', 'blatently', 'Forgive', 'hopefully', 'Freckles', 'WISH', 'laughed', 'kill', 'unny', 'blocked', 'Prayin', 'sowy', 'missing', 'Creased', 'lonesome', 'Chilling', 'Wish', 'decrease', 'ace', 'smiles', 'collapses', 'commands', 'beating', 'hurt', 'evil', 'Looking', 'yes', 'Yayy', 'BAH', 'messed', 'success', 'Trouble', 'safe', 'Yay', 'bruised', 'ADORE', 'misplaced', 'GOODNIGHT', 'OMGSH', 'hurts', 'sorted', 'upset', 'cramping', 'nicer', 'borin', 'adorable', 'brave', 'Thx', 'grrrrrrr', 'Funeral', 'darn', 'crush', 'Killed', 'infection', 'miss', 'awfully', 'nerd', 'ruin', 'liked', '-sorry', 'like', 'Lameness', 'Yayyyyyyy', 'saddens', 'lonely', 'starving', 'support', 'steal', 'addicted', 'woops', 'scariest', 'Tired', 'love', 'promise', 'lol', 'unlucky', 'disease', 'deceiving', 'victims', 'mayyyybe', 'Itchy', 'argh', 'twisted', 'goodluck', 'guilty', 'crisps', 'bullied', 'anxiety', 'witty', 'specials', 'awesome', 'missed', 'gmail', 'THANKS', 'slower', 'obsessed', 'beauty', 'Hopefully', 'develop', 'drained', 'FML', 'poo', 'Hey', 'texting', 'Missing', 'goooooood', 'HELP', 'eww', 'Hangover', 'Cleaning', 'bestie', 'error', 'favorite', 'happiest', 'broke', 'dangerous', 'Relaxing', 'Alas', 'storming', 'envy', 'trending', 'handy', 'easier', 'Best', 'stupid', '_Uh_Knee', 'HAHAHA', 'mean', 'Hahaha', 'Lovely', 'SORRY', 'bummed', 'Bleh', 'sucking', 'worst', 'beautiful', 'Chillin', 'nsty', 'real', 'nicley', 'Fab', 'quashed', 'doable', 'lunch', 'chill', 'weird', 'Congrat', 'trashed', 'cant', 'baddd', 'dam', 'Defeated', 'scared', 'LOVE', 'rejected', 'sweet', 'imo', 'believes', 'idiot', 'charged', 'nan', 'Cool', 'mad', 'handsome', 'crappy', 'picnic', 'Honored', 'stolen', 'Hilarious', 'chillin', 'Bad', 'Hurt', 'luv', 'indeed', 'thank', 'Urgh', 'cancel', 'wishes', 'Goodnight', 'looooove', 'flu', 'pleased', 'fo', 'damned', 'bulky', 'depressed', 'enjoy', 'rain', 'but', 'hates', 'Superman', 'right', 'Perfect', 'awful', 'Boredom', 'sukks', 'Let-Down', 'banged', 'depress', 'hitting', 'Delayed', 'sunburn', 'Happ', 'Suffering', 'WORST', 'lack', 'ScREW', 'damp', 'won', 'great', 'Thank', 'care', 'Hurrah', 'escaped', 'Hoping', 'Fabulous', 'rock', 'Tattered', 'fmlllll', 'Mourning', 'disproves', 'WTF', 'tired', 'offered', 'pinched', 'Fun', 'Respect', 'disturbed', 'gift', 'Great', 'Yayyy', 'Howdyyy', 'hopin', 'Regrettin', 'scarce', 'never', 'Unlucky', 'smile', 'rocked', 'shame', 'caught', 'MISS', 'greatest', 'worried', 'badly', 'arghhhh', 'fine', 'joys', 'greater', 'Rocks', 'concur', 'Bored', 'laugh', 'stole', 'sad', 'bored', 'ache', 'Oops', 'Hurts', 'neat', 'goodbye', 'Hates', 'mistake', 'spooky', 'passed', 'Sorrry', 'fun', 'nauseous', 'SUUUKS', 'bless', 'hiccups', 'regret', 'downside', 'Excited', 'hope', 'fab', 'thnx', 'misse', 'sprawled', 'Sadly', 'painfully', 'grouchy', 'hardly', 'Yessir', 'burnt', 'brilliant', 'thankyou', 'Anytime', 'winner', 'sadder', 'aches', 'YAY', 'joke', 'hateeee', 'niceee', 'Excellent', 'lame', 'ughhh', 'special', 'cute', 'promises', 'adoarble', 'CONGRATS', 'haaaate', 'iloveyou', 'goodgirl', 'Worse', 'dirty', 'loner', 'screwing', 'PRIDE', 'whoops', 'allergic', 'hopes', 'hahaha', 'coolio', 'ignore', 'standard', 'Pretty', 'Like', 'jummy', 'SIGH', 'broken', 'Wonderful', 'LOVING', 'fond', 'Love', 'lost', 'Nope', 'poor', 'canceled', 'favourite', 'patient', 'Thanxs', '_it_good', 'SUCKS', 'goodb', 'smeared', 'coooolest', 'pathetic', 'nicely', 'upgraded', 'Sick', 'uuuugh', 'May', 'Exhausted', 'weak', 'smart', 'idiots', 'doubtful', 'sadness', 'damm', '/agrees', 'awsome', 'nice', 'mess', 'forget', 'Yeah', 'ion', 'wishing', 'crooning', 'loved', 'liking', 'gorgeous', 'honour', 'Safe', 'enjoyed', 'EXCELLENT', 'snappy', 'smelly', 'freaked', 'late', 'Dang', 'oww', 'Lmfao', 'Nice', 'dropped', 'ME', 'Amazing', 'delicious', 'Clean', 'Sadness', 'EVIL', 'died', 'leaving', 'humble', 'pumped', 'illness', 'goodnight', 'pretty', 'problem', 'heartburn', 'super', 'ditch', 'Freaking', 'nonsense', 'yummmm', 'boooooo', 'Dumb', 'besties', 'dizzy', 'Goooood', 'AMAZING', 'anxious', 'Enjoying', 'squirted', 'SAD', 'COOLEST', 'enjoying', 'horrible', 'kicked', 'How', 'Fantastic', 'scare', 'expensive', 'Stuck', 'HAPPY', 'Problem', 'foad']\n",
        "\n",
        "def translate_(text):\n",
        "    if len(text.split(' '))>10:\n",
        "        for word in words_voc:\n",
        "            if word in text.split(' '):\n",
        "                return word\n",
        "    return text\n",
        "\n",
        "    # target = translate(text)\n",
        "    # return target\n",
        "    # words = nltk.word_tokenize(text)\n",
        "    # if target in words:\n",
        "    #     if target in words_voc:\n",
        "    #         return target\n",
        "    #     index = words.index(target)\n",
        "    #     words = words[index:]\n",
        "    #     return \" \".join(words)\n",
        "    # else:\n",
        "    #     return text\n",
        "test_df['res'] = test_df['text'].map(lambda x:translate_(x))\n",
        "test_df = test_df.drop(columns = ['text','sentiment'])\n",
        "# test_df = test_df.drop(columns = ['sentiment'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFaEqps4ZcgQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "1c60f4eb-a72a-4443-c59c-f5e668550351"
      },
      "source": [
        "test_df.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>res</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>I just saw a shooting star... I made my wish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>best</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>exciting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>i`ve been eating cheetos all morning..</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>thanks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>CONGRATS on graduating college!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>loved, but hated driving in pollution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>In weho! They`re are playing a lot of brit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>_NJ Oh! I`m only in my 7   I just joined Twitt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>wish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>how r u feeling? and when r u guys coming back...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>Hopefully</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>there`s a 9 year waiting list to get an appoi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>better</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>Hoping</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>Zzzz... I`m taking my mom out for breakfast to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>first night sleeping in my new home</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>haha</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>Ugh</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id                                                res\n",
              "0    0       I just saw a shooting star... I made my wish\n",
              "1    1                                               best\n",
              "2    2                                           exciting\n",
              "3    3             i`ve been eating cheetos all morning..\n",
              "4    4                                             thanks\n",
              "5    5                    CONGRATS on graduating college!\n",
              "6    6              loved, but hated driving in pollution\n",
              "7    7         In weho! They`re are playing a lot of brit\n",
              "8    8  _NJ Oh! I`m only in my 7   I just joined Twitt...\n",
              "9    9                                               wish\n",
              "10  10  how r u feeling? and when r u guys coming back...\n",
              "11  11                                          Hopefully\n",
              "12  12                                                the\n",
              "13  13   there`s a 9 year waiting list to get an appoi...\n",
              "14  14                                             better\n",
              "15  15                                             Hoping\n",
              "16  16  Zzzz... I`m taking my mom out for breakfast to...\n",
              "17  17                first night sleeping in my new home\n",
              "18  18                                               haha\n",
              "19  19                                                Ugh"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_nVIRx_Zn0V"
      },
      "source": [
        "test_df.to_csv(dir+'1117.csv',header=None,index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-NTkT_swXSs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9af8c81d-4645-49c1-f321-ecdc83fb003d"
      },
      "source": [
        "print(idx2word[243])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFefUYGbvSxx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}